"""
Servi√ßo de IA para o M√≥dulo COPILOTO
=====================================
Centraliza toda integra√ß√£o com modelos de IA generativa.

FASE 2.1 - INTEGRA√á√ÉO COM BIBLIOTECA INSTITUCIONAL:
- Consulta a biblioteca de conhecimento antes de acionar a IA
- Prioriza documentos institucionais vigentes nas respostas
- Referencia fontes institucionais explicitamente

PRINC√çPIOS INSTITUCIONAIS:
- IA atua apenas como apoio textual ao servidor
- Nenhuma a√ß√£o administrativa √© executada automaticamente
- Toda resposta √© n√£o vinculante e edit√°vel
- Sistema funciona normalmente mesmo sem IA configurada
- Nenhum dado sens√≠vel enviado sem controle expl√≠cito

GOVERNAN√áA:
- Chaves lidas exclusivamente via st.secrets
- Modo degradado quando IA n√£o dispon√≠vel
- Rastreabilidade de uso (via history_service)
- Documentos institucionais ATIVOS t√™m prioridade

AUTOR: Fase 2.1 - Biblioteca de Conhecimento
DATA: Janeiro/2026
"""

import streamlit as st
from typing import Dict, Optional, Tuple, List
from datetime import datetime
import logging

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================================
# VERIFICA√á√ÉO DE DISPONIBILIDADE DA IA
# ============================================================================

def verificar_disponibilidade_ia() -> Tuple[bool, Optional[str]]:
    """
    Verifica se a IA est√° dispon√≠vel e retorna a chave da API.
    
    Aceita dois formatos de configura√ß√£o em st.secrets:
    
    Formato 1 (estruturado):
        [openai]
        api_key = "sk-proj-..."
    
    Formato 2 (flat):
        OPENAI_API_KEY = "sk-proj-..."
    
    Returns:
        Tupla (disponivel: bool, api_key: Optional[str])
    """
    try:
        # Tenta formato estruturado: [openai] api_key = "..."
        api_key = st.secrets.get("openai", {}).get("api_key")
        
        # Se n√£o encontrou, tenta formato flat: OPENAI_API_KEY = "..."
        if not api_key:
            api_key = st.secrets.get("OPENAI_API_KEY")
        
        if not api_key:
            logger.info("IA indispon√≠vel: chave n√£o configurada em st.secrets")
            logger.info("Configure: [openai] api_key ou OPENAI_API_KEY")
            return False, None
        
        # Valida√ß√£o b√°sica da chave
        if not isinstance(api_key, str) or len(api_key) < 20:
            logger.warning("IA indispon√≠vel: chave inv√°lida")
            return False, None
        
        logger.info("IA dispon√≠vel: chave encontrada em st.secrets")
        return True, api_key
        
    except Exception as e:
        logger.error(f"Erro ao verificar disponibilidade da IA: {e}")
        return False, None


def get_status_ia() -> Dict[str, any]:
    """
    Retorna informa√ß√µes sobre o status da IA.
    
    Returns:
        Dict com status, mensagem e metadados
    """
    disponivel, _ = verificar_disponibilidade_ia()
    
    if disponivel:
        return {
            "disponivel": True,
            "mensagem": "Recurso de apoio inteligente ativo",
            "modo": "IA_ATIVA",
            "timestamp": datetime.now()
        }
    else:
        return {
            "disponivel": False,
            "mensagem": "Recurso de apoio inteligente indispon√≠vel no momento",
            "modo": "MODO_PADRAO",
            "timestamp": datetime.now()
        }


# ============================================================================
# INTEGRA√á√ÉO COM OPENAI
# ============================================================================

def consultar_biblioteca_institucional(pergunta: str) -> Tuple[List[Dict], str]:
    """
    Consulta a biblioteca institucional curada para obter contexto.
    
    FASE 2.1: Esta fun√ß√£o √© chamada ANTES de acionar a IA,
    para incluir documentos institucionais vigentes no contexto.
    
    Args:
        pergunta: Pergunta do usu√°rio
    
    Returns:
        Tupla (documentos: List[Dict], contexto_formatado: str)
    """
    try:
        from services.library_search_service import (
            buscar_documentos_relevantes,
            formatar_contexto_institucional
        )
        
        # Busca documentos relevantes
        documentos = buscar_documentos_relevantes(pergunta, limite=3)
        
        if documentos:
            contexto = formatar_contexto_institucional(documentos)
            logger.info(f"Biblioteca institucional: {len(documentos)} documentos encontrados")
            return documentos, contexto
        else:
            logger.info("Biblioteca institucional: nenhum documento relevante encontrado")
            return [], ""
            
    except Exception as e:
        logger.warning(f"Erro ao consultar biblioteca institucional: {e}")
        return [], ""


def consultar_ia_openai(
    pergunta: str,
    contexto_contrato: str,
    system_prompt: str,
    contexto_institucional: str = "",
    modelo: str = "gpt-4o-mini",
    temperatura: float = 0.3,
    max_tokens: int = 1500
) -> Optional[str]:
    """
    Consulta o modelo OpenAI com a pergunta do usu√°rio.
    
    FASE 2.1: Agora inclui contexto da biblioteca institucional.
    
    IMPORTANTE: Esta fun√ß√£o APENAS √© chamada se a IA estiver dispon√≠vel.
    
    Args:
        pergunta: Pergunta do usu√°rio
        contexto_contrato: Contexto estruturado do contrato
        system_prompt: Prompt de sistema institucional
        contexto_institucional: Contexto da biblioteca institucional (Fase 2.1)
        modelo: Modelo OpenAI a ser usado
        temperatura: Controle de criatividade (0.0 = determin√≠stico, 1.0 = criativo)
        max_tokens: Limite de tokens na resposta
        
    Returns:
        Resposta da IA ou None em caso de erro
    """
    try:
        from openai import OpenAI
        
        # Obt√©m chave (j√° validada previamente)
        _, api_key = verificar_disponibilidade_ia()
        if not api_key:
            return None
        
        # Inicializa cliente OpenAI
        client = OpenAI(api_key=api_key)
        
        # FASE 2.1: Monta prompt com prioridade institucional
        if contexto_institucional:
            conteudo_usuario = f"""Voc√™ deve responder com base priorit√°ria nos documentos institucionais abaixo.
Em caso de conflito entre documentos institucionais e outras fontes, prevalece a orienta√ß√£o institucional.
Sempre cite a fonte institucional quando usar informa√ß√µes da biblioteca.

{contexto_institucional}

---

{contexto_contrato}

---

PERGUNTA DO USU√ÅRIO:
{pergunta}"""
        else:
            # Sem documentos institucionais
            conteudo_usuario = f"""N√£o foram encontrados documentos institucionais diretamente aplic√°veis a esta pergunta.
Responda com cautela e recomende consulta a fontes oficiais quando apropriado.

{contexto_contrato}

---

PERGUNTA DO USU√ÅRIO:
{pergunta}"""
        
        # Monta mensagens
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": conteudo_usuario}
        ]
        
        logger.info(f"Consultando OpenAI (modelo: {modelo})")
        
        # Chama API
        response = client.chat.completions.create(
            model=modelo,
            messages=messages,
            temperature=temperatura,
            max_tokens=max_tokens
        )
        
        # Extrai resposta
        resposta = response.choices[0].message.content
        
        logger.info(f"Resposta recebida da IA ({len(resposta)} caracteres)")
        
        return resposta
        
    except ImportError:
        logger.error("Biblioteca 'openai' n√£o instalada. Execute: pip install openai")
        return None
        
    except Exception as e:
        logger.error(f"Erro ao consultar OpenAI: {e}")
        return None


# ============================================================================
# INTERFACE PRINCIPAL DO SERVI√áO
# ============================================================================

def processar_pergunta_com_ia(
    pergunta: str,
    contrato: Dict,
    system_prompt: str
) -> Tuple[str, Dict]:
    """
    Processa pergunta usando IA (se dispon√≠vel) ou modo padr√£o.
    
    Esta √© a fun√ß√£o principal do servi√ßo, chamada pelo agente.
    
    Args:
        pergunta: Pergunta do usu√°rio
        contrato: Dados do contrato
        system_prompt: Prompt institucional
        
    Returns:
        Tupla (resposta: str, metadata: Dict)
        - resposta: Texto da resposta
        - metadata: Informa√ß√µes sobre o processamento
    """
    # Verifica disponibilidade
    disponivel, api_key = verificar_disponibilidade_ia()
    
    if not disponivel:
        # Modo degradado: retorna mensagem institucional
        metadata = {
            "modo": "MODO_PADRAO",
            "ia_disponivel": False,
            "timestamp": datetime.now(),
            "mensagem_sistema": "IA n√£o configurada - operando em modo padr√£o"
        }
        
        resposta_padrao = """
ü§ñ **Recurso de Apoio Inteligente Indispon√≠vel**

No momento, o recurso de apoio inteligente n√£o est√° dispon√≠vel.

**Informa√ß√µes do Contrato:**
- N√∫mero: {numero}
- Fornecedor: {fornecedor}
- Objeto: {objeto}

**Como obter ajuda:**
- Consulte a p√°gina **"üìñ Como Proceder"** para orienta√ß√µes gerais
- Acesse a **"üìö Biblioteca"** para consultar manuais institucionais
- Entre em contato com a equipe de suporte t√©cnico

üí° *Administradores: Para ativar o recurso de IA, configure a chave da API em `st.secrets`*
        """.format(
            numero=contrato.get('numero', '(n√£o informado)'),
            fornecedor=contrato.get('fornecedor', '(n√£o informado)'),
            objeto=contrato.get('objeto', '(n√£o informado)')
        )
        
        return resposta_padrao, metadata
    
    # FASE 2.1: Consulta biblioteca institucional ANTES de chamar a IA
    documentos_institucionais, contexto_institucional = consultar_biblioteca_institucional(pergunta)
    
    # Monta contexto do contrato
    from agents.copilot_agent import extrair_contexto_contrato
    contexto_contrato = extrair_contexto_contrato(contrato)
    
    # Consulta IA com contexto institucional
    resposta_ia = consultar_ia_openai(
        pergunta=pergunta,
        contexto_contrato=contexto_contrato,
        system_prompt=system_prompt,
        contexto_institucional=contexto_institucional
    )
    
    if resposta_ia:
        # Sucesso: retorna resposta da IA
        metadata = {
            "modo": "IA_ATIVA",
            "ia_disponivel": True,
            "timestamp": datetime.now(),
            "mensagem_sistema": "Resposta gerada por IA generativa",
            "documentos_institucionais_usados": len(documentos_institucionais),
            "biblioteca_consultada": len(documentos_institucionais) > 0
        }
        
        # FASE 2.1: Adiciona refer√™ncias institucionais se houver
        if documentos_institucionais:
            referencias = "\n".join([
                f"- {doc['referencia']}" for doc in documentos_institucionais
            ])
            rodape_institucional = f"""
---

üìö **Fontes Institucionais Consultadas:**
{referencias}

‚ö†Ô∏è **IMPORTANTE:** Esta resposta foi gerada por IA com base em documentos institucionais vigentes. N√£o constitui orienta√ß√£o jur√≠dica vinculante. Sempre valide as informa√ß√µes com fontes oficiais e consulte as cl√°usulas contratuais originais.
            """
        else:
            rodape_institucional = """
---

‚ÑπÔ∏è *N√£o foram encontrados documentos institucionais diretamente aplic√°veis a esta pergunta.*

‚ö†Ô∏è **IMPORTANTE:** Esta resposta foi gerada por IA como apoio textual. N√£o constitui orienta√ß√£o jur√≠dica vinculante. Sempre valide as informa√ß√µes com fontes oficiais e consulte as cl√°usulas contratuais originais.
            """
        
        resposta_final = f"{resposta_ia}{rodape_institucional}"
        
        return resposta_final, metadata
    else:
        # Erro na IA: retorna mensagem de fallback
        metadata = {
            "modo": "ERRO_IA",
            "ia_disponivel": True,
            "timestamp": datetime.now(),
            "mensagem_sistema": "Erro ao processar com IA - consulte logs"
        }
        
        resposta_erro = """
‚ö†Ô∏è **Erro ao Processar Solicita√ß√£o**

N√£o foi poss√≠vel processar sua pergunta com o recurso de apoio inteligente no momento.

**Alternativas:**
- Reformule sua pergunta e tente novamente
- Consulte a p√°gina **"üìñ Como Proceder"**
- Acesse a **"üìö Biblioteca"** para manuais institucionais
- Entre em contato com o suporte t√©cnico

üí° *Se o problema persistir, entre em contato com os administradores do sistema.*
        """
        
        return resposta_erro, metadata


# ============================================================================
# REGISTRO DE USO (GOVERNAN√áA)
# ============================================================================

def registrar_uso_copiloto(
    contrato_id: str,
    metadata: Dict,
    usuario: Optional[str] = None
) -> None:
    """
    Registra uso do COPILOTO para fins de governan√ßa.
    
    N√ÉO armazena conte√∫do da pergunta ou resposta (privacidade).
    Armazena apenas metadados estat√≠sticos.
    
    Args:
        contrato_id: ID do contrato consultado
        metadata: Metadados do processamento
        usuario: ID do usu√°rio (opcional)
    """
    try:
        from services.history_service import registrar_evento
        
        evento = {
            "tipo": "COPILOTO_CONSULTA_REALIZADA",
            "contrato_id": contrato_id,
            "modo": metadata.get("modo", "DESCONHECIDO"),
            "ia_disponivel": metadata.get("ia_disponivel", False),
            "timestamp": metadata.get("timestamp", datetime.now()),
            "usuario": usuario or "n√£o identificado"
        }
        
        registrar_evento(evento)
        logger.info(f"Uso do COPILOTO registrado: {evento['modo']}")
        
    except Exception as e:
        # Falha no registro n√£o deve impedir funcionamento
        logger.warning(f"Erro ao registrar uso do COPILOTO: {e}")


# ============================================================================
# UTILIT√ÅRIOS
# ============================================================================

def get_modelos_disponiveis() -> list:
    """
    Retorna lista de modelos OpenAI dispon√≠veis para uso institucional.
    
    Returns:
        Lista de identificadores de modelos
    """
    return [
        "gpt-4o-mini",      # Recomendado: barato, r√°pido, bom custo-benef√≠cio
        "gpt-4o",           # Mais poderoso, mais caro
        "gpt-4-turbo",      # Balanceado
        "gpt-3.5-turbo"     # Mais barato, menos sofisticado
    ]


def get_parametros_recomendados() -> Dict[str, any]:
    """
    Retorna par√¢metros recomendados para uso institucional.
    
    Returns:
        Dict com par√¢metros
    """
    return {
        "modelo": "gpt-4o-mini",
        "temperatura": 0.3,      # Baixa criatividade, alta consist√™ncia
        "max_tokens": 1000,      # Respostas concisas
        "top_p": 0.9,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0
    }
